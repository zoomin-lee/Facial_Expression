{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"A3eI3j_5mbuE"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUesa5XNtGGW"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import math\n","import os\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0QSxZ3Ny2zV"},"outputs":[],"source":["# @markdown #Load *UNBC-McMaster shoulder pain* Dataset\n","\n","!mkdir -p '/content/dataset/UNBCMcMaster/'\n","!cp '/content/drive/MyDrive/UNBC-McMaster/Images.zip' './dataset/UNBCMcMaster/'\n","!cp '/content/drive/MyDrive/UNBC-McMaster/AAM_landmarks.zip' './dataset/UNBCMcMaster/'\n","!cp '/content/drive/MyDrive/UNBC-McMaster/Frame_Labels.zip' './dataset/UNBCMcMaster/'\n","!cp '/content/drive/MyDrive/UNBC-McMaster/Sequence_Labels.zip' './dataset/UNBCMcMaster/'\n","\n","!unzip -q './dataset/UNBCMcMaster/Images.zip' -d './dataset/UNBCMcMaster/'\n","!unzip -q './dataset/UNBCMcMaster/AAM_landmarks.zip' -d './dataset/UNBCMcMaster/'\n","!unzip -q './dataset/UNBCMcMaster/Frame_Labels.zip' -d '/content/dataset/UNBCMcMaster/'\n","!unzip -q './dataset/UNBCMcMaster/Sequence_Labels.zip' -d '/content/dataset/UNBCMcMaster/'"]},{"cell_type":"markdown","metadata":{"id":"36c0JmbxqkHY"},"source":["# Data Loader & Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T9rJF2aeFTBZ"},"outputs":[],"source":["class UNBCMcMaster(tf.keras.utils.Sequence):\n","    def __init__(self, x_dir, y_dir, keys, test_subj_id, subset, label='vas'):\n","        \"\"\" UNBC McMaster Shoulder Pain Dataset\n","        Args:\n","            x_dir (str): path to the landmark data\n","            y_dir (str): path to the label (pain level)\n","            keys ([str]): list of subject ids. ex) ['042']\n","            test_subj_id ([str]): list of subject ids. ex) ['042']\n","            subset (str): train / val / test\n","        \"\"\"\n","        assert subset in ['train', 'test']\n","        assert label in ['vas', 'pspi']\n","\n","        self.LMpath = x_dir\n","        self.VASpath = os.path.join(y_dir, 'Sequence_Labels', 'VAS')\n","        self.PSPIpath = os.path.join(y_dir, 'Frame_Labels', 'PSPI')\n","        self.landmark_files = [(root, name) for root, dirs, files in os.walk(self.LMpath) for\n","                               name in sorted(files) if name[-3:] == 'txt' and\n","                               ((name[2:5] in test_subj_id and subset=='test') or\n","                                (not(name[2:5] in test_subj_id) and name[2:5] in keys and subset=='train'))]\n","        self.label = label\n","\n","    def __len__(self):\n","        return len(self.landmark_files)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"return sample\n","            landmark: a list of 1434(=478*3) values -> 132 for aam\n","            vas_score: float [0.0, 1.0, ... , 10.0]\n","            pspi_score: float [0.0, 1.0, ... , 15.0]\n","\n","            subj_id: ex) '106-nm106'\n","            video_id: ex) 'nm106t1aeunaff'\n","            landmark_id: ex) 'nm106t1aeunaff001.json' -> txt for aam\n","        \"\"\"\n","        lm_dir = self.landmark_files[idx][0]\n","        lm_name = self.landmark_files[idx][1]\n","\n","        landmark = []\n","        with open(os.path.join(lm_dir, lm_name), 'r') as lm_txt:\n","            lm_data = lm_txt.readlines()\n","        for line in lm_data:\n","            line = line.strip()\n","            line = line.split()\n","            landmark.extend([float(i) for i in line])\n","\n","        landmark_id = lm_name\n","        video_dir = os.path.split(lm_dir)\n","        video_id = video_dir[1]\n","        subj_dir = os.path.split(video_dir[0])\n","        subj_id = subj_dir[1]\n","\n","        name = os.path.join(self.VASpath, subj_id, video_id)\n","        with open(name + '.txt', 'r') as vas_txt:\n","            vas_str = vas_txt.read()\n","        vas_score = float(vas_str[:vas_str.find('e')]) * (10 ** int(vas_str[vas_str.find('+')+1:]))\n","\n","        name = os.path.join(self.PSPIpath, subj_id, video_id, lm_name[:-8]+'_facs')\n","        with open(name + '.txt', 'r') as pspi_txt:\n","            pspi_str = pspi_txt.read()\n","        pspi_score = float(pspi_str[:pspi_str.find('e')]) * (10 ** int(pspi_str[pspi_str.find('+')+1:]))\n","  \n","        if self.label == 'vas':\n","            return np.array([landmark]), np.array([vas_score])\n","        else:\n","            return np.array([landmark]), np.array([pspi_score])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pg4Wf8upNtlQ"},"outputs":[],"source":["class DeepFaceLIFT(tf.keras.Model):\n","    def __init__(self):\n","        super(DeepFaceLIFT, self).__init__()\n","        self.dense_1 = tf.keras.layers.Dense(units=300, activation='relu')\n","        self.dense_2 = tf.keras.layers.Dense(units=100, activation='relu')\n","        self.dense_3 = tf.keras.layers.Dense(units=10, activation='relu')\n","        self.dense_4 = tf.keras.layers.Dense(units=100, activation='relu')\n","        self.linear = tf.keras.layers.Dense(units=1, activation='linear')\n","\n","    def call(self, inputs):\n","        out = self.dense_1(inputs)\n","        out = self.dense_2(out)\n","        out = self.dense_3(out)\n","        out = self.dense_4(out)\n","        out = self.linear(out)\n","        return out\n","\n","    def summary(self, print_fn=None):\n","        x = tf.keras.Input(shape=(132))\n","        model = tf.keras.Model(x, self.call(x))\n","        return model.summary(print_fn=print_fn)"]},{"cell_type":"markdown","metadata":{"id":"xvIsUx1Dq0x_"},"source":["# settings"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"0_o1AUHd0QAC"},"outputs":[],"source":["strategy = tf.distribute.get_strategy()\n","print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","BATCH_SIZE = 8 #@param{type:'number'}\n","print('BATCH_SIZE:', BATCH_SIZE)\n","\n","EPOCHS = 100  #@param {type: 'number'}\n","LEARNING_RATE = 1e-5  #@param {type: 'number'}\n","\n","KFOLDS = 5  #@param {type:'number'}\n","SHUFFLE = True  #@param {type:'boolean'}\n","RANDOM_STATE =   100#@param {type:'raw'}\n","\n","X_DIR = '/content/dataset/UNBCMcMaster/AAM_landmarks'  #@param {type: 'string'}\n","Y_DIR = '/content/dataset/UNBCMcMaster/'  #@param {type: 'string'}\n","\n","TEST_SUBJECTS = '042, 123' #@param {type: 'string'}\n","test_subjects = TEST_SUBJECTS.split(', ')\n","print('test_subjects:', test_subjects)"]},{"cell_type":"markdown","metadata":{"id":"a-vgJvpG6rf7"},"source":["# Callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTYYYpVMgVQF"},"outputs":[],"source":["from moviepy.editor import *\n","import cv2\n","from matplotlib import animation\n","from matplotlib.animation import FuncAnimation\n","import matplotlib.pyplot as plt\n","from tempfile import NamedTemporaryFile\n","\n","def moviefy_results(test_frames_path, test_true, test_pred, label, out_path):\n","    \"\"\"\n","    Args:\n","        test_frames_path: path to test frames\n","        test_true: a list of ground truth labels for each frame (VAS or PSPI)\n","        test_pred: a list of predicted value\n","        label: 'vas' or 'pspi'\n","    Return:\n","        result video .mp4 \n","    \"\"\"\n","    assert label in ['vas', 'pspi']\n","\n","    frames = len(test_pred)\n","\n","    if label == 'vas':\n","        max_score, ylabel = 15, 'VAS'\n","        test_true = test_true * frames\n","    else:\n","        max_score, ylabel = 20, 'PSPI'\n","    \n","\n","    test_frames = [os.path.join(test_frames_path, f) for f in os.listdir(test_frames_path) if \n","                   f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","    test_frames = sorted(test_frames)\n","\n","    patient_clip = ImageSequenceClip(test_frames, fps=30)\n","\n","    fig, ax = plt.subplots()\n","    ax.set_ylim((0, max_score))\n","    ax.set_xlabel('Frames')\n","    ax.set_ylabel(ylabel)\n","\n","    x = np.arange(frames)\n","    y_true = test_true\n","    y_pred = test_pred\n","\n","    plt.plot(x, y_true, label='Ground Truth')\n","    plt.xlabel('Frames')\n","    plt.ylabel(ylabel)\n","\n","    line_1, = ax.plot(x, y_pred, label='Prediction')\n","\n","    def update(i, x, y_pred, line_1):\n","        line_1.set_data(x[:i], y_pred[:i])\n","        line_1.axes.axis([0, frames, 0, 15])\n","        line_1.set_label(ylabel)\n","\n","        plt.legend(loc='upper right')\n","        ax.set_title(f'{ylabel}: {y_pred[i]:.2f}')\n","\n","        return line_1,\n","\n","    plot_ani = FuncAnimation(fig, update,\n","                        fargs=[x, y_pred, line_1],\n","                        blit=False, \n","                        frames=np.arange(frames),\n","                        interval=33,\n","                        save_count=frames)\n","    \n","    with NamedTemporaryFile(suffix='.mp4') as f1, NamedTemporaryFile(suffix='.mp4') as f2:\n","        patient_clip.write_videofile(f1.name)\n","        plot_ani.save(f2.name, writer=animation.FFMpegWriter(fps=30))\n","\n","        clip1 = VideoFileClip(f1.name).resize(height=240)\n","        clip2 = VideoFileClip(f2.name).resize(height=240)\n","        clips = [[clip1, clip2]]\n","        clip_out = clips_array(clips)\n","\n","    plt.close()\n","\n","    clip_out.write_videofile(out_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-v3LTYlnPYWA"},"outputs":[],"source":["checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path, \n","    verbose=1, \n","    save_weights_only=True,\n","    save_freq='epoch')"]},{"cell_type":"markdown","metadata":{"id":"VihAYyUK6of0"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QjPqt0eDKmmi"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","\n","tf.keras.backend.clear_session()\n","\n","# subject folder names\n","subjects = []\n","for d in next(os.walk(X_DIR))[1]:\n","    subjects.append(d[:3])\n","subjects = sorted(subjects)\n","\n","for ts in test_subjects:\n","    subjects.remove(ts)\n","\n","print('train/val subjects cnt:', len(subjects), '\\ntest_subject:', test_subjects)\n","\n","\n","kf = KFold(n_splits=KFOLDS, shuffle=SHUFFLE, random_state=RANDOM_STATE)\n","subjects = np.array(subjects)\n","\n","for fold, (train_idx, valid_idx) in enumerate(kf.split(subjects)):\n","    print(f'\\n++++++++++ Fold {fold+1}/{KFOLDS} ++++++++++')\n","\n","    with strategy.scope():\n","        model = DeepFaceLIFT()\n","        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n","                      loss='mean_squared_error',\n","                      metrics='mean_absolute_error')\n","    \n","    history = model.fit(UNBCMcMaster(x_dir=X_DIR,\n","                                     y_dir=Y_DIR,\n","                                     keys=subjects[train_idx],\n","                                     test_subj_id=test_subjects,\n","                                     subset='train',\n","                                     label='pspi'),\n","                        epochs=EPOCHS,\n","                        batch_size=BATCH_SIZE,\n","                        validation_data=UNBCMcMaster(x_dir=X_DIR,\n","                                                     y_dir=Y_DIR,\n","                                                     keys=subjects[valid_idx],\n","                                                     test_subj_id=test_subjects,\n","                                                     subset='train',\n","                                                     label='pspi'),\n","                        callbacks=[\n","                                #    RemoteLogger(),\n","                                   cp_callback,\n","                                #    RemoteSaveCheckpoint(),\n","                                   ],\n","                        )\n"]},{"cell_type":"code","source":["!cp /content/training -r /content/drive/MyDrive/smctmp-ckpt"],"metadata":{"id":"Rec3i9IdCPOQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## AAM\n","sample_paths = [\n","                '/content/dataset/UNBCMcMaster/Images/043-jh043/jh043t2aaaff',\n","                '/content/dataset/UNBCMcMaster/Images/047-jl047/jl047t1aaaff',\n","                '/content/dataset/UNBCMcMaster/Images/092-ch092/ch092t1aiaff',\n","                ]\n","\n","sample_json_paths = ['/content/dataset/UNBCMcMaster/AAM_landmarks/043-jh043/jh043t2aaaff',\n","                    '/content/dataset/UNBCMcMaster/AAM_landmarks/047-jl047/jl047t1aaaff',\n","                    '/content/dataset/UNBCMcMaster/AAM_landmarks/092-ch092/ch092t1aiaff',\n","                     ]\n","\n","# # VAS\n","# sample_label_paths = ['/content/dataset/UNBCMcMaster/Sequence_Labels/VAS/042-ll042/ll042t1aiaff',\n","#                       '/content/dataset/UNBCMcMaster/Sequence_Labels/VAS/123-jh123/jh123t1aeaff',\n","#                       ]\n","\n","# sample_true = []\n","# for sample_label in sample_label_paths:\n","#     with open(sample_label + '.txt', 'r') as vas_txt:\n","#         vas_str = vas_txt.read()\n","#     vas_score = float(vas_str[:vas_str.find('e')]) * (10 ** int(vas_str[vas_str.find('+')+1:]))\n","#     sample_true.append([vas_score])\n","\n","# PSPI\n","sample_label_paths = ['/content/dataset/UNBCMcMaster/Frame_Labels/PSPI/043-jh043/jh043t2aaaff',\n","                      '/content/dataset/UNBCMcMaster/Frame_Labels/PSPI/047-jl047/jl047t1aaaff',\n","                      '/content/dataset/UNBCMcMaster/Frame_Labels/PSPI/092-ch092/ch092t1aiaff',\n","                      ]\n","\n","sample_true = []\n","for sample_label in sample_label_paths:\n","    sample_pspi_seq = []\n","    for sample_pspi in os.listdir(sample_label):\n","        with open(os.path.join(sample_label, sample_pspi), 'r') as pspi_txt:\n","            pspi_str = pspi_txt.read()\n","        pspi_score = float(pspi_str[:pspi_str.find('e')]) * (10 ** int(pspi_str[pspi_str.find('+')+1:]))\n","        sample_pspi_seq.extend([pspi_score])\n","    sample_true.append(sample_pspi_seq)\n","\n","## AAM\n","sample_landmark = []\n","for sample_path in sample_json_paths:\n","    sample_lm_seq = []\n","    for sample_txt in os.listdir(sample_path):\n","        sample_lm_frame = []\n","        with open(os.path.join(sample_path, sample_txt), 'r') as lm_txt:\n","            lm_data = lm_txt.readlines()\n","            for line in lm_data:\n","                line = line.strip()\n","                line = line.strip()\n","                line = line.split()\n","                sample_lm_frame.extend([float(i) for i in line])\n","        sample_lm_seq.append(sample_lm_frame)\n","    sample_landmark.append(sample_lm_seq)\n","\n","\n","    \n","for i in range(len(sample_paths)):\n","    test_pred_seq = []\n","    for j in range(len(sample_landmark[i])):\n","        test_pred = model.predict([sample_landmark[i][j]])\n","        test_pred_seq.extend(test_pred[0])\n","\n","    moviefy_results(sample_paths[i],\n","                    test_true=sample_true[i],\n","                    test_pred=test_pred_seq,\n","                    label='pspi',\n","                    out_path=f'/content/tmp-{i}.mp4'\n","                    )"],"metadata":{"id":"EqBNbKYbuOiX"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"share_DeepFaceLIFT-UNBC-aam_pspi.ipynb의 사본","provenance":[{"file_id":"1uAqBO_u94995UFsd1vQP1crQ33zx3uy4","timestamp":1639752104069},{"file_id":"1H8cG59gRgIPDu54yVXSYFVKPWJsiHWyf","timestamp":1639649504332},{"file_id":"1LZFUPcnx-kwv5Kjmo5k07gOGWbSDzbGK","timestamp":1639640342917},{"file_id":"1UvXerEivJxECqd3v3uIt2qmU-Xyww5V5","timestamp":1639635953043},{"file_id":"1xG_cLGpck8iSeo3FdcvXXMSN26VJ5kBd","timestamp":1639565891018}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}